{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap\n",
    "import socket\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely.geometry import box \n",
    "from shapely.geometry import mapping\n",
    "import re # regular expressions\n",
    "import folium\n",
    "from folium import GeoJson\n",
    "from folium.plugins import MarkerCluster\n",
    "from rasterio.merge import merge\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import geometry_mask\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "def setup_directories():\n",
    "    # check if we are on the server or local\n",
    "    nodename = socket.gethostname()\n",
    "    if nodename == \"oMac.local\": # local laptop\n",
    "        root = os.path.expanduser(\"~/OneDrive - The University of Chicago/guatamala_ag/data\")\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment, Please specify the root directory\")\n",
    "\n",
    "    dirs = {\n",
    "        'root': root,\n",
    "        'raw': os.path.join(root, \"raw\"),\n",
    "        'processed': os.path.join(root, \"processed\"),\n",
    "        'fig': os.path.join(root, \"../figures\")\n",
    "    }\n",
    "\n",
    "    for path in dirs.values():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    return dirs\n",
    "\n",
    "dir = setup_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Coordinate data and then convert to geopandas, and calculate area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed 1 occurrences of approximately 90.366662 to -90.366662 in longitude_4\n",
      "Fixed 1 occurrences of approximately 5.267439 to 15.267439 in latitude_1\n",
      "Fixed 1 occurrences of approximately -16.35262 to -90.163562 in longitude_1\n",
      "\n",
      "Total rows with all valid coordinates: 125 out of 125\n",
      "\n",
      "Data processing complete. Results saved to 'coordinates_processed.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohouck/envs/guatamala_venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:223: UserWarning: Cell LH147 is marked as a date but the serial value 6729160 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "def add_decimal_if_missing(coord):\n",
    "    if isinstance(coord, str) and coord.replace('-', '').isdigit():\n",
    "        if coord.startswith('-'):\n",
    "            return f\"-{coord[1:3]}.{coord[3:]}\"\n",
    "        else:\n",
    "            return f\"{coord[:2]}.{coord[2:]}\"\n",
    "    return coord\n",
    "\n",
    "def is_valid_guatemala_coordinate(lat, lon):\n",
    "    # Approximate bounding box for Guatemala\n",
    "    return 13.1 <= lat <= 18.2 and -93 <= lon <= -88.0\n",
    "\n",
    "def fix_known_coordinate_issues(df):\n",
    "    \"\"\"\n",
    "    Fix known coordinate issues in the dataframe using approximate floating-point comparisons.\n",
    "    \"\"\"\n",
    "    known_fixes = {\n",
    "        ('longitude_4', 90.366662): -90.366662,\n",
    "        ('latitude_1', 5.267439): 15.267439,\n",
    "        ('longitude_1', -16.352620): -90.1635620,\n",
    "    }\n",
    "    \n",
    "    for (col, incorrect_value), correct_value in known_fixes.items():\n",
    "        # Use numpy's isclose for approximate floating-point comparison\n",
    "        mask = np.isclose(df[col], incorrect_value, rtol=1e-5, atol=1e-8)\n",
    "        if mask.any():\n",
    "            df.loc[mask, col] = correct_value\n",
    "            print(f\"Fixed {mask.sum()} occurrences of approximately {incorrect_value} to {correct_value} in {col}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def split_coordinates(coord_str):\n",
    "    # Existing manual fixes\n",
    "    manual_fixes = {\n",
    "        \"16,3870407, -89,7345351\": \"16.3870407, -89.7345351\",\n",
    "        \"14.177150.3,-90.3989608\": \"14.1771503, -90.3989608\",\n",
    "        \"16,3869101, -89,7344694\": \"16.3869101, -89.7344694\",\n",
    "        \"14.141996-90-147208\": \"14.141996, -90.147208\",\n",
    "        \"16,3871767, -89,7348127\": \"16.3871767, -89.7348127\",\n",
    "        \"16,3869863, -89,7349780\": \"16.3869863, -89.7349780\"\n",
    "    }\n",
    "    \n",
    "    if coord_str in manual_fixes:\n",
    "        coord_str = manual_fixes[coord_str]\n",
    "    \n",
    "    # Remove any quotation marks and leading/trailing whitespace\n",
    "    cleaned = coord_str.strip().strip('\"')\n",
    "    \n",
    "    # Try to match various patterns\n",
    "    patterns = [\n",
    "        r'^([-]?\\d+\\.?\\d*)[,\\s]+([-]?\\d+\\.?\\d*)$',  # Comma or space separated\n",
    "        r'^([-]?\\d+\\.?\\d*)\\.([-]?\\d+\\.?\\d*)$',      # Period separated\n",
    "        r'^(\\d+\\.?\\d*)(-\\d+\\.?\\d*)$'                # No separator with negative longitude\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        # if we get passed the first pattern, remove all whitespace\n",
    "        cleaned = re.sub(r'\\s', '', cleaned)\n",
    "        match = re.match(pattern, cleaned)\n",
    "        if match:\n",
    "            lat, lon = match.group(1), match.group(2)\n",
    "            lat = add_decimal_if_missing(lat)\n",
    "            lon = add_decimal_if_missing(lon)\n",
    "            return pd.Series({'latitude': lat, 'longitude': lon})\n",
    "    \n",
    "    # If we couldn't split it, return empty strings\n",
    "    print(f\"Could not split coordinates: {coord_str}\")\n",
    "    return pd.Series({'latitude': '', 'longitude': ''})\n",
    "\n",
    "df = pd.read_excel(os.path.join(dir['raw'], \"Datos de Impacto Productores 2023.xlsx\"), \n",
    "    sheet_name= 0, skiprows=4)\n",
    "vars_to_keep = [\"id_phone\", \"id_coordinates_1\", \"id_coordinates_2\", \n",
    "                \"id_coordinates_3\", \"id_coordinates_4\"]\n",
    "df = df[vars_to_keep]\n",
    "# drop rows with missing id_coordinates_1\n",
    "df = df.dropna(subset=[\"id_coordinates_1\"])\n",
    "\n",
    "\n",
    "# Process coordinates\n",
    "for i in range(1, 5):\n",
    "    col_name = f'id_coordinates_{i}'\n",
    "    new_cols = df[col_name].apply(split_coordinates)\n",
    "    df[f'latitude_{i}'] = pd.to_numeric(new_cols['latitude'], errors='coerce')\n",
    "    df[f'longitude_{i}'] = pd.to_numeric(new_cols['longitude'], errors='coerce')\n",
    "    \n",
    "    # Check if coordinates are within Guatemala's range\n",
    "    df[f'valid_coordinate_{i}'] = df.apply(\n",
    "        lambda row: is_valid_guatemala_coordinate(row[f'latitude_{i}'], row[f'longitude_{i}']), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# Fix known coordinate issues\n",
    "df = fix_known_coordinate_issues(df)\n",
    "\n",
    "# Recheck validity after fixes\n",
    "for i in range(1, 5):\n",
    "    df[f'valid_coordinate_{i}'] = df.apply(\n",
    "        lambda row: is_valid_guatemala_coordinate(row[f'latitude_{i}'], row[f'longitude_{i}']), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# Print summary of remaining invalid coordinates\n",
    "for i in range(1, 5):\n",
    "    invalid_coords = df[~df[f'valid_coordinate_{i}']]\n",
    "    if not invalid_coords.empty:\n",
    "        print(f\"\\nRemaining invalid coordinates for id_coordinates_{i}:\")\n",
    "        print(invalid_coords[[f'latitude_{i}', f'longitude_{i}']])\n",
    "\n",
    "# Check if all coordinates are valid\n",
    "all_valid = df.apply(lambda row: all(row[f'valid_coordinate_{i}'] for i in range(1, 5)), axis=1)\n",
    "print(f\"\\nTotal rows with all valid coordinates: {all_valid.sum()} out of {len(df)}\")\n",
    "\n",
    "# Save the processed data\n",
    "df.to_csv(os.path.join(dir['processed'], \"coordinates_processed.csv\"), index=False)\n",
    "print(\"\\nData processing complete. Results saved to 'coordinates_processed.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with area over 500k sqm: 8\n",
      "\n",
      "GeoDataFrame shape: (117, 24)\n",
      "GeoDataFrame CRS: EPSG:5459\n",
      "count       117.00\n",
      "mean      12407.17\n",
      "std       31590.46\n",
      "min           0.00\n",
      "25%        1884.04\n",
      "50%        4174.59\n",
      "75%       10579.19\n",
      "max      243667.68\n",
      "Name: area_sqm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create lat and lon min and max columns\n",
    "df['lat_min'] = df[['latitude_1', 'latitude_2', 'latitude_3', 'latitude_4']].min(axis=1)\n",
    "df['lat_max'] = df[['latitude_1', 'latitude_2', 'latitude_3', 'latitude_4']].max(axis=1)\n",
    "df['lon_min'] = df[['longitude_1', 'longitude_2', 'longitude_3', 'longitude_4']].min(axis=1)\n",
    "df['lon_max'] = df[['longitude_1', 'longitude_2', 'longitude_3', 'longitude_4']].max(axis=1)\n",
    "\n",
    "# Function to create a polygon from min/max coordinates\n",
    "# jury is out on which is better\n",
    "def create_polygon(row):\n",
    "    return box(row['lon_min'], row['lat_min'], row['lon_max'], row['lat_max'])\n",
    "\n",
    "# Alternative Function to create a polygon from coordinates\n",
    "# def create_polygon(row):\n",
    "#     coords = [\n",
    "#         (float(row['longitude_1']), float(row['latitude_1'])),\n",
    "#         (float(row['longitude_2']), float(row['latitude_2'])),\n",
    "#         (float(row['longitude_3']), float(row['latitude_3'])),\n",
    "#         (float(row['longitude_4']), float(row['latitude_4'])),\n",
    "#         (float(row['longitude_1']), float(row['latitude_1']))  # Close the polygon\n",
    "#     ]\n",
    "#     return Polygon(coords)\n",
    "\n",
    "\n",
    "# Create the geometry column\n",
    "df['geometry'] = df.apply(create_polygon, axis=1)\n",
    "\n",
    "crs = \"EPSG:5459\" # crs for guatemala\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=crs)\n",
    "\n",
    "# Function to calculate area in square meters\n",
    "def calculate_area(geometry, lat):\n",
    "    # Define a local projection centered on the polygon\n",
    "    local_azimuthal_projection = f\"+proj=aeqd +lat_0={lat}\\\n",
    "        +lon_0={geometry.centroid.x} +x_0=0 +y_0=0\"\n",
    "    \n",
    "    # Create a GeoSeries with the input geometry and set its CRS\n",
    "    geoseries = gpd.GeoSeries([geometry], crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Project the GeoSeries to the local azimuthal equidistant projection\n",
    "    projected_geoseries = geoseries.to_crs(local_azimuthal_projection)\n",
    "    \n",
    "    # Get the projected geometry and calculate its area\n",
    "    projected_geometry = projected_geoseries.iloc[0]\n",
    "\n",
    "    area = projected_geometry.area\n",
    "\n",
    "    # check if area is nan\n",
    "    if pd.isna(area):\n",
    "        print(f\"Area is nan for {geometry}\")\n",
    "        # print the lat and lon\n",
    "        print(f\"Lat: {lat}, Lon: {geometry.centroid.x}\")\n",
    "        return\n",
    "\n",
    "    return area \n",
    "\n",
    "# create an id column\n",
    "gdf['id'] = range(len(gdf))\n",
    "\n",
    "# Calculate area for each polygon\n",
    "gdf['area_sqm'] = gdf.apply(lambda row: calculate_area(row['geometry'], \n",
    "                            row['geometry'].centroid.y), axis=1)\n",
    "\n",
    "# count number of rows with area over 1 million sqm\n",
    "print(f\"Number of rows with area over 500k sqm: {len(gdf[gdf['area_sqm'] > 500_000])}\")\n",
    "\n",
    "# drop rows with area over 0.5 million sqm (5k by 5k meters)\n",
    "gdf = gdf[gdf['area_sqm'] < 500_000]\n",
    "\n",
    "# Display info about the GeoDataFrame\n",
    "print(f\"\\nGeoDataFrame shape: {gdf.shape}\")\n",
    "print(f\"GeoDataFrame CRS: {gdf.crs}\")\n",
    "\n",
    "# print summary statistics for area and round to 2 decimal places\n",
    "print(gdf['area_sqm'].describe().round(2))\n",
    "\n",
    "# save the geodataframe\n",
    "gdf.to_file(os.path.join(dir['processed'], \"cleaned_parcels.geojson\"), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Pull Sentinel 2 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentinel2_imagery_multi(geometries, ids, start_date, end_date, output_dir, \n",
    "                                bands_to_save, max_cloud_cover=10):\n",
    "    ee.Initialize()\n",
    "\n",
    "    \n",
    "    for geom, id in zip(geometries, ids):\n",
    "        try:\n",
    "            ee_geometry = ee.Geometry.Polygon(list(geom.exterior.coords))\n",
    "            \n",
    "            s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "                             .filterBounds(ee_geometry)\n",
    "                             .filterDate(start_date, end_date)\n",
    "                             .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover)))\n",
    "            \n",
    "            if s2_collection.size().getInfo() == 0:\n",
    "                print(f\"No images found for geometry {id}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # normalized difference vegetation index\n",
    "            def addNDVI(image):\n",
    "                ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "                return image.addBands(ndvi)\n",
    "\n",
    "            # green chlorophyl vegetation index (not using but used in SCYM)\n",
    "            def addGCVI(image):\n",
    "                gcvi = image.normalizedDifference(['B8', 'B3']).rename('GCVI')  # B8: NIR, B3: Green\n",
    "                return image.addBands(gcvi)\n",
    "\n",
    "            # Sort by NDVI and select the image with the highest NDVI\n",
    "            s2_collection = s2_collection.sort('NDVI', False)\n",
    "            selected_image = ee.Image(s2_collection.first())\n",
    "            \n",
    "            clipped = selected_image.clip(ee_geometry)\n",
    "            output_file = os.path.join(output_dir, f\"sentinel_image_{id}.tif\")\n",
    "\n",
    "            geemap.ee_export_image(clipped, filename=output_file, scale=10, region=ee_geometry)\n",
    "\n",
    "            # Save band information\n",
    "            band_info = {i+1: name for i, name in enumerate(bands_to_save)}\n",
    "            with open(os.path.join(output_dir, f\"sentinel_image_{id}_bands.json\"), 'w') as f:\n",
    "                json.dump(band_info, f)\n",
    "            \n",
    "            print(f\"Sentinel image for geometry {id} saved to {output_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing geometry {id}: {str(e)}\")\n",
    "\n",
    "    print(\"All individual Sentinel images have been saved.\")\n",
    "\n",
    "# Usage\n",
    "geometries = gdf.geometry.tolist()\n",
    "ids = gdf.id.tolist()\n",
    "\n",
    "# take 10 percent sample for testing\n",
    "geometries = geometries[::10]\n",
    "ids = ids[::10]\n",
    "\n",
    "output_dir = os.path.join(dir['processed'], \"sentinel_images\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# currently saving all bands but might not be necessary\n",
    "bands_to_save = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', \n",
    "                    'B9', 'B10', 'B11', 'B12', \"NDVI\", \"id\"]\n",
    "\n",
    "get_sentinel2_imagery_multi(geometries, ids, '2023-01-01', '2023-06-30', \n",
    "                            output_dir, bands_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'B1', '2': 'B2', '3': 'B3', '4': 'B4', '5': 'B5', '6': 'B6', '7': 'B7', '8': 'B8', '9': 'B8A', '10': 'B9', '11': 'B10', '12': 'B11', '13': 'B12', '14': 'NDVI', '15': 'id'}\n",
      "{'driver': 'GTiff', 'dtype': 'uint32', 'nodata': None, 'width': 4, 'height': 3, 'count': 23, 'crs': CRS.from_epsg(32615), 'transform': Affine(10.0, 0.0, 798610.0,\n",
      "       0.0, -10.0, 1632110.0)}\n"
     ]
    }
   ],
   "source": [
    "# read in a single raster to test\n",
    "raster = rasterio.open(os.path.join(output_dir, \"sentinel_image_10.tif\"))\n",
    "\n",
    "# combine with the bands info\n",
    "with open(os.path.join(output_dir, \"sentinel_image_10_bands.json\"), 'r') as f:\n",
    "    bands = json.load(f)\n",
    "\n",
    "# print band info\n",
    "print(bands)\n",
    "\n",
    "# print raster info\n",
    "print(raster.meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine pulled Sentinel images into a single raster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available bands: ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B10', 'B11', 'B12', 'NDVI', 'id']\n",
      "Bands to be saved: ['B2', 'B3', 'B4', 'B8', 'NDVI']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined raster saved to /Users/ohouck/OneDrive - The University of Chicago/guatamala_ag/data/processed/merged_sentinel_image.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.merge import merge\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import box\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"TIFFReadDirectory\")\n",
    "\n",
    "def get_band_info(file_path):\n",
    "    json_path = file_path.rsplit('.', 1)[0] + '_bands.json'\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "def combine_tif_files(input_dir, output_file, bands_to_save):\n",
    "    # Get all .tif files in the input directory\n",
    "    tif_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.tif')]\n",
    "    \n",
    "    # Initialize lists to store the bounds and open dataset objects\n",
    "    bounds_list = []\n",
    "    src_files_to_mosaic = []\n",
    "    band_info_list = []\n",
    "    \n",
    "    # Open all files and collect their bounds and band info\n",
    "    for file in tif_files:\n",
    "        src = rasterio.open(file)\n",
    "        bounds_list.append(src.bounds)\n",
    "        src_files_to_mosaic.append(src)\n",
    "        band_info = get_band_info(file)\n",
    "        if band_info:\n",
    "            band_info_list.append(band_info)\n",
    "        else:\n",
    "            print(f\"Warning: No band info found for {file}\")\n",
    "    \n",
    "    # Determine available bands from band info\n",
    "    if band_info_list:\n",
    "        available_bands = list(band_info_list[0].values())\n",
    "        print(f\"Available bands: {available_bands}\")\n",
    "    else:\n",
    "        available_bands = src_files_to_mosaic[0].descriptions\n",
    "        print(f\"Warning: Using default band names. Available bands: {available_bands}\")\n",
    "    \n",
    "    # Filter bands_to_save to only include available bands\n",
    "    bands_to_save = [band for band in bands_to_save if band in available_bands]\n",
    "    if not bands_to_save:\n",
    "        raise ValueError(\"None of the specified bands are available in the source files.\")\n",
    "    \n",
    "    print(f\"Bands to be saved: {bands_to_save}\")\n",
    "    \n",
    "    # Read the first file to get the metadata\n",
    "    meta = src_files_to_mosaic[0].meta.copy()\n",
    "    \n",
    "    # Update the metadata for the output file\n",
    "    meta.update({\n",
    "        'count': len(bands_to_save),\n",
    "        'nodata': 0,\n",
    "        'dtype': 'float32'\n",
    "    })\n",
    "    \n",
    "    # Calculate the overall bounds\n",
    "    bounds = rasterio.coords.BoundingBox(\n",
    "        left=min(bound.left for bound in bounds_list),\n",
    "        bottom=min(bound.bottom for bound in bounds_list),\n",
    "        right=max(bound.right for bound in bounds_list),\n",
    "        top=max(bound.top for bound in bounds_list)\n",
    "    )\n",
    "    \n",
    "    # Create a mask for the farm parcels\n",
    "    mask_shape = box(*bounds)\n",
    "    geo = GeoDataFrame({'geometry': [mask_shape]}, crs=src_files_to_mosaic[0].crs)\n",
    "    \n",
    "    try:\n",
    "        # Perform the mosaic operation\n",
    "        mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "        \n",
    "        # Update the metadata with the new transform and shape\n",
    "        meta.update({\n",
    "            \"height\": mosaic.shape[1],\n",
    "            \"width\": mosaic.shape[2],\n",
    "            \"transform\": out_trans\n",
    "        })\n",
    "\n",
    "        # Create a mask for areas outside the farm parcels\n",
    "        mask = geometry_mask([mapping(geo.geometry.iloc[0])], out_shape=mosaic.shape[1:], transform=out_trans, invert=True)\n",
    "        \n",
    "        # Apply the mask to the mosaic\n",
    "        mosaic = np.ma.masked_array(mosaic, np.broadcast_to(mask, mosaic.shape))\n",
    "        \n",
    "        # Write the output file\n",
    "        with rasterio.open(output_file, \"w\", **meta) as dest:\n",
    "            for i, band_name in enumerate(bands_to_save):\n",
    "                if band_info_list:\n",
    "                    band_index = list(band_info_list[0].values()).index(band_name)\n",
    "                else:\n",
    "                    band_index = available_bands.index(band_name)\n",
    "                dest.write(mosaic[band_index], i+1)\n",
    "                dest.set_band_description(i+1, band_name)\n",
    "        \n",
    "        print(f\"Combined raster saved to {output_file}\")\n",
    "    \n",
    "    finally:\n",
    "        # Close all opened raster files\n",
    "        for src in src_files_to_mosaic:\n",
    "            src.close()\n",
    "\n",
    "\n",
    "    \n",
    "# Usage\n",
    "input_dir = os.path.join(dir['processed'], \"sentinel_images\")\n",
    "output_file = os.path.join(dir['processed'], \"merged_sentinel_image.tif\")\n",
    "bands_to_save = ['B2', 'B3', 'B4', 'B8', 'NDVI']  # Adjust as needed\n",
    "\n",
    "combine_tif_files(input_dir, output_file, bands_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Interactive Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import folium\n",
    "from folium import raster_layers\n",
    "import geopandas as gpd\n",
    "from rasterio.warp import transform_bounds\n",
    "from pyproj import Transformer\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def create_interactive_map(raster_file, parcel_file, output_file, max_zoom=10):\n",
    "    try:\n",
    "        logging.info(\"Starting to create interactive map\")\n",
    "        \n",
    "        # Read the raster file\n",
    "        with rasterio.open(raster_file) as src:\n",
    "            logging.info(f\"Opened raster file: {raster_file}\")\n",
    "            \n",
    "            # Get raster metadata without reading all the data\n",
    "            bounds = src.bounds\n",
    "            transform = src.transform\n",
    "            crs = src.crs\n",
    "            \n",
    "            # Transform bounds to lat/lon (EPSG:4326)\n",
    "            transformer = Transformer.from_crs(crs, \"EPSG:4326\", always_xy=True)\n",
    "            minx, miny = transformer.transform(bounds.left, bounds.bottom)\n",
    "            maxx, maxy = transformer.transform(bounds.right, bounds.top)\n",
    "        \n",
    "        logging.info(\"Transformed raster bounds to lat/lon\")\n",
    "\n",
    "        # Read the parcel shapefile\n",
    "        parcels = gpd.read_file(parcel_file)\n",
    "        logging.info(f\"Read parcel file: {parcel_file}\")\n",
    "\n",
    "        # Create a map centered on the raster data\n",
    "        m = folium.Map(location=[(miny + maxy) / 2, (minx + maxx) / 2], zoom_start=min(10, max_zoom))\n",
    "\n",
    "        # Add the raster layer as a TileLayer for memory efficiency\n",
    "        url = f\"http://localhost:8080/raster/{os.path.basename(raster_file)}\" + \"/{z}/{x}/{y}.png\"\n",
    "        raster_layer = folium.raster_layers.TileLayer(\n",
    "            tiles=url,\n",
    "            attr=\"Raster Data\",\n",
    "            name=\"Raster Layer\",\n",
    "            overlay=True,\n",
    "            opacity=0.7\n",
    "        )\n",
    "        raster_layer.add_to(m)\n",
    "\n",
    "        logging.info(\"Added raster layer to map\")\n",
    "\n",
    "        # Add parcel boundaries\n",
    "        folium.GeoJson(\n",
    "            parcels,\n",
    "            name=\"Farm Parcels\",\n",
    "            style_function=lambda feature: {\n",
    "                'fillColor': 'blue',\n",
    "                'color': 'black',\n",
    "                'weight': 2,\n",
    "                'fillOpacity': 0.1,\n",
    "            }\n",
    "        ).add_to(m)\n",
    "\n",
    "        logging.info(\"Added parcel boundaries to map\")\n",
    "\n",
    "        # Add a layer control\n",
    "        folium.LayerControl().add_to(m)\n",
    "\n",
    "        # Save the map\n",
    "        m.save(output_file)\n",
    "        logging.info(f\"Interactive map saved to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\", exc_info=True)\n",
    "        raise\n",
    "\n",
    "raster_file = os.path.join(dir['processed'], \"merged_sentinel_image.tif\")\n",
    "parcel_file= os.path.join(dir['processed'], \"cleaned_parcels.geojson\") \n",
    "output_file = os.path.join(dir['fig'], \"interactive_map.html\")\n",
    "\n",
    "create_interactive_map(raster_file, parcel_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guatamala_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
