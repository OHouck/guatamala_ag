---
title: "Guatemala Parcels EDA"
author: "Ozzy Houck"
date: today
format: 
   html 
execute:
  eval: false 
  echo: false
---

### Set up
```{python}
import os
import ee
import geemap
import socket
import pandas as pd
import numpy as np
import geopandas as gpd
import rasterio
from shapely.geometry import box 
from shapely.geometry import mapping
import re # regular expressions
import folium
from folium import GeoJson
from folium.plugins import MarkerCluster
from rasterio.merge import merge
from rasterio.mask import mask
from rasterio.features import geometry_mask
import json
import warnings

def setup_directories():
    # check if we are on the server or local
    nodename = socket.gethostname()
    if nodename == "oMac.local": # local laptop
        root = os.path.expanduser("~/OneDrive - The University of Chicago/guatamala_ag/data")
    else:
        raise Exception("Unknown environment, Please specify the root directory")

    dirs = {
        'root': root,
        'raw': os.path.join(root, "raw"),
        'processed': os.path.join(root, "processed"),
        'fig': os.path.join(root, "../figures")
    }

    for path in dirs.values():
        os.makedirs(path, exist_ok=True)

    return dirs

dir = setup_directories()

```

### Clean Coordinates

```{python}
def add_decimal_if_missing(coord):
    if isinstance(coord, str) and coord.replace('-', '').isdigit():
        if coord.startswith('-'):
            return f"-{coord[1:3]}.{coord[3:]}"
        else:
            return f"{coord[:2]}.{coord[2:]}"
    return coord

def is_valid_guatemala_coordinate(lat, lon):
    # Approximate bounding box for Guatemala
    return 13.1 <= lat <= 18.2 and -93 <= lon <= -88.0

def fix_known_coordinate_issues(df):
    """
    Fix known coordinate issues in the dataframe using approximate floating-point comparisons.
    """
    known_fixes = {
        ('longitude_4', 90.366662): -90.366662,
        ('latitude_1', 5.267439): 15.267439,
        ('longitude_1', -16.352620): -90.1635620,
    }
    
    for (col, incorrect_value), correct_value in known_fixes.items():
        # Use numpy's isclose for approximate floating-point comparison
        mask = np.isclose(df[col], incorrect_value, rtol=1e-5, atol=1e-8)
        if mask.any():
            df.loc[mask, col] = correct_value
            print(f"Fixed {mask.sum()} occurrences of approximately {incorrect_value} to {correct_value} in {col}")
    
    return df

def split_coordinates(coord_str):
    # Existing manual fixes
    manual_fixes = {
        "16,3870407, -89,7345351": "16.3870407, -89.7345351",
        "14.177150.3,-90.3989608": "14.1771503, -90.3989608",
        "16,3869101, -89,7344694": "16.3869101, -89.7344694",
        "14.141996-90-147208": "14.141996, -90.147208",
        "16,3871767, -89,7348127": "16.3871767, -89.7348127",
        "16,3869863, -89,7349780": "16.3869863, -89.7349780"
    }
    
    if coord_str in manual_fixes:
        coord_str = manual_fixes[coord_str]
    
    # Remove any quotation marks and leading/trailing whitespace
    cleaned = coord_str.strip().strip('"')
    
    # Try to match various patterns
    patterns = [
        r'^([-]?\d+\.?\d*)[,\s]+([-]?\d+\.?\d*)$',  # Comma or space separated
        r'^([-]?\d+\.?\d*)\.([-]?\d+\.?\d*)$',      # Period separated
        r'^(\d+\.?\d*)(-\d+\.?\d*)$'                # No separator with negative longitude
    ]
    
    for pattern in patterns:
        # if we get passed the first pattern, remove all whitespace
        cleaned = re.sub(r'\s', '', cleaned)
        match = re.match(pattern, cleaned)
        if match:
            lat, lon = match.group(1), match.group(2)
            lat = add_decimal_if_missing(lat)
            lon = add_decimal_if_missing(lon)
            return pd.Series({'latitude': lat, 'longitude': lon})
    
    # If we couldn't split it, return empty strings
    print(f"Could not split coordinates: {coord_str}")
    return pd.Series({'latitude': '', 'longitude': ''})

df = pd.read_excel(os.path.join(dir['raw'], "Datos de Impacto Productores 2023.xlsx"), 
    sheet_name= 0, skiprows=4)
vars_to_keep = ["id_phone", "id_coordinates_1", "id_coordinates_2", 
                "id_coordinates_3", "id_coordinates_4"]
df = df[vars_to_keep]
# drop rows with missing id_coordinates_1
df = df.dropna(subset=["id_coordinates_1"])


# Process coordinates
for i in range(1, 5):
    col_name = f'id_coordinates_{i}'
    new_cols = df[col_name].apply(split_coordinates)
    df[f'latitude_{i}'] = pd.to_numeric(new_cols['latitude'], errors='coerce')
    df[f'longitude_{i}'] = pd.to_numeric(new_cols['longitude'], errors='coerce')
    
    # Check if coordinates are within Guatemala's range
    df[f'valid_coordinate_{i}'] = df.apply(
        lambda row: is_valid_guatemala_coordinate(row[f'latitude_{i}'], row[f'longitude_{i}']), 
        axis=1
    )

# Fix known coordinate issues
df = fix_known_coordinate_issues(df)

# Recheck validity after fixes
for i in range(1, 5):
    df[f'valid_coordinate_{i}'] = df.apply(
        lambda row: is_valid_guatemala_coordinate(row[f'latitude_{i}'], row[f'longitude_{i}']), 
        axis=1
    )

# Print summary of remaining invalid coordinates
for i in range(1, 5):
    invalid_coords = df[~df[f'valid_coordinate_{i}']]
    if not invalid_coords.empty:
        print(f"\nRemaining invalid coordinates for id_coordinates_{i}:")
        print(invalid_coords[[f'latitude_{i}', f'longitude_{i}']])

# Check if all coordinates are valid
all_valid = df.apply(lambda row: all(row[f'valid_coordinate_{i}'] for i in range(1, 5)), axis=1)
print(f"\nTotal rows with all valid coordinates: {all_valid.sum()} out of {len(df)}")

# Save the processed data
df.to_csv(os.path.join(dir['processed'], "coordinates_processed.csv"), index=False)
print("\nData processing complete. Results saved to 'coordinates_processed.csv'.")
```

### Convert to GeoDataFrame and Calculate Area
```{python}
# create lat and lon min and max columns
df['lat_min'] = df[['latitude_1', 'latitude_2', 'latitude_3', 'latitude_4']].min(axis=1)
df['lat_max'] = df[['latitude_1', 'latitude_2', 'latitude_3', 'latitude_4']].max(axis=1)
df['lon_min'] = df[['longitude_1', 'longitude_2', 'longitude_3', 'longitude_4']].min(axis=1)
df['lon_max'] = df[['longitude_1', 'longitude_2', 'longitude_3', 'longitude_4']].max(axis=1)

# Function to create a polygon from min/max coordinates
# jury is out on which is better
def create_polygon(row):
    return box(row['lon_min'], row['lat_min'], row['lon_max'], row['lat_max'])

# Alternative Function to create a polygon from coordinates
# def create_polygon(row):
#     coords = [
#         (float(row['longitude_1']), float(row['latitude_1'])),
#         (float(row['longitude_2']), float(row['latitude_2'])),
#         (float(row['longitude_3']), float(row['latitude_3'])),
#         (float(row['longitude_4']), float(row['latitude_4'])),
#         (float(row['longitude_1']), float(row['latitude_1']))  # Close the polygon
#     ]
#     return Polygon(coords)


# Create the geometry column
df['geometry'] = df.apply(create_polygon, axis=1)

crs = "EPSG:5459" # crs for guatemala
gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=crs)

# Function to calculate area in square meters
def calculate_area(geometry, lat):
    # Define a local projection centered on the polygon
    local_azimuthal_projection = f"+proj=aeqd +lat_0={lat}\
        +lon_0={geometry.centroid.x} +x_0=0 +y_0=0"
    
    # Create a GeoSeries with the input geometry and set its CRS
    geoseries = gpd.GeoSeries([geometry], crs="EPSG:4326")
    
    # Project the GeoSeries to the local azimuthal equidistant projection
    projected_geoseries = geoseries.to_crs(local_azimuthal_projection)
    
    # Get the projected geometry and calculate its area
    projected_geometry = projected_geoseries.iloc[0]

    area = projected_geometry.area

    # check if area is nan
    if pd.isna(area):
        print(f"Area is nan for {geometry}")
        # print the lat and lon
        print(f"Lat: {lat}, Lon: {geometry.centroid.x}")
        return

    return area 

# create an id column
gdf['id'] = range(len(gdf))

# Calculate area for each polygon
gdf['area_sqm'] = gdf.apply(lambda row: calculate_area(row['geometry'], 
                            row['geometry'].centroid.y), axis=1)

# count number of rows with area over 1 million sqm
print(f"Number of rows with area over 500k sqm: {len(gdf[gdf['area_sqm'] > 500_000])}")

# drop rows with area over 0.5 million sqm (5k by 5k meters)
gdf = gdf[gdf['area_sqm'] < 500_000]

# Display info about the GeoDataFrame
print(f"\nGeoDataFrame shape: {gdf.shape}")
print(f"GeoDataFrame CRS: {gdf.crs}")

# print summary statistics for area and round to 2 decimal places
print(gdf['area_sqm'].describe().round(2))

# save the geodataframe
gdf.to_file(os.path.join(dir['processed'], "cleaned_parcels.geojson"), driver='GeoJSON')

# create geometry object of all parcels for plotting in earth engine
ee_geometry = ee.Geometry.MultiPolygon(list(gdf.geometry.apply(lambda x: mapping(x)))) # XX this causes a KeyError: 0 error
```


### Create Interactive Map showing sentenial 2 imagery and parcel boundaries using GEE
```{python}
# Initialize Earth Engine
ee.Initialize()

# Create an interactive map
Map = geemap.Map()

# Load the Sentinel-2 image collection
s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR')
                 .filterDate('2023-01-01', '2023-06-30')
                 .filterBounds(ee.FeatureCollection(gdf.__geo_interface__))
                 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))
                 .select(['B4', 'B3', 'B2']))

# Create a median composite
s2_median = s2_collection.median()

clipped = s2_median.clip(ee_geometry)

# Add the Sentinel-2 layer
Map.addLayer(s2_median, {'min': 0, 'max': 3000}, 'Sentinel-2 Median')

# Add the farm parcels
Map.add_gdf(gdf, layer_name = 'Farm Parcels', fill_colors=['red'])


# Display the map
Map.save(os.path.join(dir['fig'], 'interactive_map_geemap.html'))
print(f"Interactive map saved to {os.path.join(dir['fig'], 'interactive_map_geemap.html')}")
```

### Pull Sentinel 2 Imagery from Google Earth Engine

```{python}
def get_sentinel2_imagery_multi(geometries, ids, start_date, end_date, output_dir, 
                                bands_to_save, max_cloud_cover=10):
    ee.Initialize()

    
    for geom, id in zip(geometries, ids):
        try:
            ee_geometry = ee.Geometry.Polygon(list(geom.exterior.coords))
            
            s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR')
                             .filterBounds(ee_geometry)
                             .filterDate(start_date, end_date)
                             .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover)))
            
            if s2_collection.size().getInfo() == 0:
                print(f"No images found for geometry {id}. Skipping.")
                continue

            # normalized difference vegetation index
            def addNDVI(image):
                ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')
                return image.addBands(ndvi)

            # green chlorophyl vegetation index (not using but used in SCYM)
            def addGCVI(image):
                gcvi = image.normalizedDifference(['B8', 'B3']).rename('GCVI')  # B8: NIR, B3: Green
                return image.addBands(gcvi)

            # Add NDVI band
            s2_collection = s2_collection.map(addNDVI)

            # Sort by NDVI and select the image with the highest NDVI
            s2_collection = s2_collection.sort('NDVI', False)
            selected_image = ee.Image(s2_collection.first())
            
            clipped = selected_image.clip(ee_geometry)
            output_file = os.path.join(output_dir, f"sentinel_image_{id}.tif")

            geemap.ee_export_image(clipped, filename=output_file, scale=10, region=ee_geometry)

            # Save band information
            band_info = {i+1: name for i, name in enumerate(bands_to_save)}
            with open(os.path.join(output_dir, f"sentinel_image_{id}_bands.json"), 'w') as f:
                json.dump(band_info, f)
            
            print(f"Sentinel image for geometry {id} saved to {output_file}")
            
        except Exception as e:
            print(f"Error processing geometry {id}: {str(e)}")

    print("All individual Sentinel images have been saved.")

# Usage
geometries = gdf.geometry.tolist()
ids = gdf.id.tolist()

# # take 10 percent sample for testing
geometries = geometries[::10]
ids = ids[::10]

output_dir = os.path.join(dir['processed'], "sentinel_images")
os.makedirs(output_dir, exist_ok=True)

# currently saving all bands but might not be necessary
bands_to_save = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 
                    'B9', 'B10', 'B11', 'B12', "NDVI", "id"]

get_sentinel2_imagery_multi(geometries, ids, '2023-01-01', '2023-06-30', 
                            output_dir, bands_to_save)
```

```{python}
import rasterio
from rasterio.merge import merge
import glob
import os

# Define the directory containing your Sentinel-2 images
input_dir = os.path.join(dir['processed'], "sentinel_images")

# Get a list of all .tif files
tif_files = glob.glob(os.path.join(input_dir, 'sentinel_image_*.tif'))

# Open all the images
src_files_to_mosaic = []
for tif in tif_files:
    src = rasterio.open(tif)
    src_files_to_mosaic.append(src)

# Merge them into a single mosaic
mosaic, out_trans = merge(src_files_to_mosaic)

# Update the metadata
out_meta = src.meta.copy()
out_meta.update({
    "driver": "GTiff",
    "height": mosaic.shape[1],
    "width": mosaic.shape[2],
    "transform": out_trans,
    "crs": src.crs
})

# Write the mosaic to disk
mosaic_path = os.path.join(input_dir, "sentinel_mosaic.tif")
with rasterio.open(mosaic_path, "w", **out_meta) as dest:
    dest.write(mosaic)

print(f"Mosaic saved to {mosaic_path}")
```









### Combine TIF Files into a single raster (OLD CODE )

```{python}
import os
import rasterio
from rasterio.merge import merge
from rasterio.warp import calculate_default_transform, reproject, Resampling

def combine_tif_files(input_dir, output_file, bands_to_save, dst_crs=None):
    # Get all the tif files from the input directory
    tif_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.tif')]

    # Open all the tif files
    src_files_to_mosaic = [rasterio.open(f) for f in tif_files]

    # Merge the files into a mosaic
    mosaic, out_transform = merge(src_files_to_mosaic)

    # Get metadata from the first file and update it for the mosaic
    out_meta = src_files_to_mosaic[0].meta.copy()
    out_meta.update({
        "driver": "GTiff",
        "height": mosaic.shape[1],
        "width": mosaic.shape[2],
        "transform": out_transform,
        "count": len(bands_to_save)  # Update to the number of bands you're saving
    })

    # If a destination CRS is provided, reproject the mosaic
    if dst_crs:
        # Calculate the transform for the new CRS
        transform, width, height = calculate_default_transform(
            src_files_to_mosaic[0].crs, dst_crs, out_meta['width'], out_meta['height'], *src_files_to_mosaic[0].bounds
        )
        out_meta.update({
            'crs': dst_crs,
            'transform': transform,
            'width': width,
            'height': height
        })

        # Create an empty array to hold the reprojected mosaic
        reprojected_mosaic = rasterio.open(output_file, 'w', **out_meta)
        reproject(
            source=mosaic,
            destination=rasterio.band(reprojected_mosaic, 1),
            src_transform=out_transform,
            src_crs=src_files_to_mosaic[0].crs,
            dst_transform=transform,
            dst_crs=dst_crs,
            resampling=Resampling.nearest
        )
        reprojected_mosaic.close()
    else:
        # Write the merged raster without reprojection
        with rasterio.open(output_file, "w", **out_meta) as dest:
            dest.write(mosaic)

    # Close all the open files
    for src in src_files_to_mosaic:
        src.close()

# Usage
input_dir = os.path.join(dir['processed'], "sentinel_images")
output_file = os.path.join(dir['processed'], "merged_sentinel_image.tif")
bands_to_save = ['B2', 'B3', 'B4', 'B8', 'NDVI']  # Adjust as needed

combine_tif_files(input_dir, output_file, bands_to_save)
```

### Create interactive map with folium

```{python}
import rasterio
import geopandas as gpd
import matplotlib.pyplot as plt

def verify_data(raster_file, parcel_file):
    # Check raster data
    with rasterio.open(raster_file) as src:
        print(f"Raster CRS: {src.crs}")
        print(f"Raster Bounds: {src.bounds}")
        print(f"Raster Shape: {src.shape}")
        
        # Plot the first band of the raster
        plt.figure(figsize=(10, 10))
        plt.imshow(src.read(1), cmap='viridis')
        plt.title("First Band of Raster Data")
        plt.colorbar()
        plt.savefig("raster_preview.png")
        plt.close()

    # Check parcel data
    parcels = gpd.read_file(parcel_file)
    print(f"Parcels CRS: {parcels.crs}")
    print(f"Number of parcels: {len(parcels)}")
    print(f"Parcels Bounds: {parcels.total_bounds}")
    
    # Plot parcels
    parcels.plot(figsize=(10, 10))
    plt.title("Parcel Boundaries")
    plt.savefig("parcels_preview.png")
    plt.close()

    return parcels

# Use the function
raster_file = os.path.join(dir['processed'], "merged_sentinel_image.tif")
parcel_file = os.path.join(dir['processed'], "cleaned_parcels.geojson")
parcels = verify_data(raster_file, parcel_file)

# Check if parcels intersect with raster
with rasterio.open(raster_file) as src:
    raster_bounds = src.bounds
    raster_geom = gpd.GeoDataFrame({'geometry': [box(*raster_bounds)]}, crs=src.crs)
    parcels_reprojected = parcels.to_crs(src.crs)
    intersection = gpd.overlay(parcels_reprojected, raster_geom, how='intersection')
    print(f"Number of parcels intersecting with raster: {len(intersection)}")

```

```{python}
import os
import rasterio
import numpy as np
import folium
from folium import raster_layers
import geopandas as gpd
from rasterio.warp import transform_bounds
from pyproj import Transformer
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def create_interactive_map(raster_file, parcel_file, output_file, max_zoom=18):
    try:
        logging.info("Starting to create interactive map")
        
        # Read the raster file
        with rasterio.open(raster_file) as src:
            logging.info(f"Opened raster file: {raster_file}")
            
            # Get raster metadata without reading all the data
            bounds = src.bounds
            transform = src.transform
            crs = src.crs
            
            # Transform bounds to lat/lon (EPSG:4326)
            transformer = Transformer.from_crs(crs, "EPSG:4326", always_xy=True)
            minx, miny = transformer.transform(bounds.left, bounds.bottom)
            maxx, maxy = transformer.transform(bounds.right, bounds.top)
        
        logging.info("Transformed raster bounds to lat/lon")

        # Read the parcel shapefile
        parcels = gpd.read_file(parcel_file)
        logging.info(f"Read parcel file: {parcel_file}")

         # Get the centroid of the first parcel
        first_parcel_centroid = parcels.iloc[0].geometry.centroid
        center_lat, center_lon = first_parcel_centroid.y, first_parcel_centroid.x

        # Create a map centered on the first parcel
        m = folium.Map(location=[center_lat, center_lon], zoom_start=16, max_zoom=max_zoom)

        # Add the raster layer as a TileLayer for memory efficiency
        url = f"http://localhost:8080/raster/{os.path.basename(raster_file)}" + "/{z}/{x}/{y}.png"
        raster_layer = folium.raster_layers.TileLayer(
            tiles=url,
            attr="Raster Data",
            name="Raster Layer",
            overlay=True,
            opacity=0.7
        )
        raster_layer.add_to(m)

        logging.info("Added raster layer to map")

        # Add parcel boundaries
        folium.GeoJson(
            parcels,
            name="Farm Parcels",
            style_function=lambda feature: {
                'fillColor': 'blue',
                'color': 'black',
                'weight': 2,
                'fillOpacity': 0.1,
            }
        ).add_to(m)

        logging.info("Added parcel boundaries to map")

        # Add a layer control
        folium.LayerControl().add_to(m)

        # Save the map
        m.save(output_file)
        logging.info(f"Interactive map saved to {output_file}")

    except Exception as e:
        logging.error(f"An error occurred: {str(e)}", exc_info=True)
        raise

raster_file = os.path.join(dir['processed'], "merged_sentinel_image.tif")
parcel_file= os.path.join(dir['processed'], "cleaned_parcels.geojson") 
output_file = os.path.join(dir['fig'], "interactive_map.html")

create_interactive_map(raster_file, parcel_file, output_file)
```